{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetinaNet on Segmind Edge (>0.3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get started\n",
    "\n",
    "- [Install Edge](https://docs.segmind.com/installation)\n",
    "- [Configure Edge](https://docs.segmind.com/configure)\n",
    "- [Use sample dataset](https://docs.segmind.com/test-datasets)\n",
    "\n",
    "Update the paths to paths on your machine and you are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import set_project_name, set_workspace\n",
    "\n",
    "set_project_name(\"project_name\")\n",
    "set_workspace(\"/path/to/project/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Analytics\n",
    "\n",
    "This is a mandatory step to be run before training. It provides you statistics on training data, which will help you set the hyper-parameters for retinanet. It also creates project related files needed later during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge.detection import get_analytics\n",
    "from pprint import pprint\n",
    "\n",
    "analytics_result = get_analytics(\n",
    "        image_dir = \"/path/to/jpgs/folder\",\n",
    "        annotation_dir = \"/path/to/xml/folder\",\n",
    ")\n",
    "\n",
    "pprint(analytics_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge.detection.retinanet import train\n",
    "\n",
    "train(\n",
    "    resize_height=600,\n",
    "    resize_width=600,\n",
    "    num_epochs=200,\n",
    "    batch_size=2,\n",
    "    checkpoint_prefix=\"try1\",\n",
    "    snapshot_every_epoch=10,\n",
    "    steps_per_epoch=None,\n",
    "    sizes=[16,32,64,128, 256],\n",
    "    strides=[8,16,32,64,128],\n",
    "    ratios=[0.5,1,2.0],\n",
    "    scales=[1,1.25,1.5],\n",
    "    initial_epoch=0,\n",
    "    weights='imagenet',\n",
    "    aug=None\n",
    "    backbone_network='resnet50',\n",
    "    lr=1e-5,\n",
    "    print_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting inference & drawing it on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge.detection.retinanet import get_inference_model, image_predict\n",
    "\n",
    "checkpoint = \"path_to_checkpoint\"\n",
    "image_path = \"path_to_image_for_inference\"\n",
    "\n",
    "# Load the model\n",
    "model = get_inference_model(checkpoint)\n",
    "\n",
    "# Use the loaded instance to get predictions\n",
    "detections = image_predict(image_path, model)\n",
    "\n",
    "from edge.detection import draw_bboxes\n",
    "\n",
    "image = draw_bboxes(image_path,\n",
    "  bboxes=detections['boxes'],\n",
    "  labels=detections['labels'],\n",
    "  scores=detections['scores'],\n",
    "  threshold=0.5,\n",
    "  label_dict=None)\n",
    "\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
