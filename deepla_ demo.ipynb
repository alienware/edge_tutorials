{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip MULTI_CLASS_SEGM_DEMO.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import set_project_name, set_workspace\n",
    "set_project_name(\"deeplab_demo\")\n",
    "set_workspace(\"/tmp\")\n",
    "\n",
    "from edge.segmentation.deeplab_v3.evaluation import CocoEvaluator\n",
    "\n",
    "from edge.segmentation.deeplab_v3 import train\n",
    "from edge.metrics.cocostuff_modules.cocostuffeval import COCOStuffeval\n",
    "from edge.segmentation.deeplab_v3 import get_inference_model\n",
    "from edge.mlflowlite_logger import get_experiment_id\n",
    "\n",
    "from mlflow_lite import set_experiment\n",
    "from mlflow_lite import log_metrics\n",
    "set_experiment('521e7ebc-36c9-4ae8-8507-f7b31a5bd963_19')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "\n",
    "from logzero import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = 'MULTI_CLASS_SEGM_DEMO/TRAIN/IMAGES'\n",
    "train_annotations = 'MULTI_CLASS_SEGM_DEMO/TRAIN/MASK'\n",
    "\n",
    "eval_images = 'MULTI_CLASS_SEGM_DEMO/TEST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analytics phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 88.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTotal images for training: 500\u001b[0m\n",
      "{'black_images': 0,\n",
      " 'label_mappings': {'1': 1,\n",
      "                    '10': 9,\n",
      "                    '11': 10,\n",
      "                    '12': 11,\n",
      "                    '13': 12,\n",
      "                    '14': 13,\n",
      "                    '15': 14,\n",
      "                    '2': 2,\n",
      "                    '255': 15,\n",
      "                    '3': 3,\n",
      "                    '4': 4,\n",
      "                    '5': 5,\n",
      "                    '6': 6,\n",
      "                    '7': 7,\n",
      "                    '8': 8},\n",
      " 'negative_images': 0,\n",
      " 'num_classes': 15,\n",
      " 'positive_images': 500,\n",
      " 'total': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from edge.segmentation import get_analytics\n",
    "from pprint import pprint\n",
    "\n",
    "analytics_result = get_analytics(\n",
    "        image_dir = train_images,\n",
    "        annotation_dir = train_annotations\n",
    ")\n",
    "\n",
    "pprint(analytics_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:10<00:00, 45.55it/s]\n",
      "100%|██████████| 500/500 [02:37<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from edge.segmentation import prepare_data\n",
    "from edge.metrics import convert_pascalvoc_coco\n",
    "\n",
    "prepare_data()\n",
    "\n",
    "convert_pascalvoc_coco(\n",
    "    image_dir=train_images,\n",
    "    annotation_dir=train_annotations,\n",
    "    coco_gt_path='/tmp/segm_gt.json',\n",
    "    iouType='segm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:00:20 <ipython-input-3-fecc709d05cb>:20] Logging to mlflow-lite under exp-id 521e7ebc-36c9-4ae8-8507-f7b31a5bd963_19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py:330: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py:330: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py:330: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:00:20 <ipython-input-3-fecc709d05cb>:20] Logging to mlflow-lite under exp-id 521e7ebc-36c9-4ae8-8507-f7b31a5bd963_19\n",
      "2020/04/26 12:00:21 WARNING mlflow_lite.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mlogged training data to server\u001b[0m\n",
      "Train on 500 steps\n",
      "Epoch 1/5\n",
      "199/500 [==========>...................] - ETA: 2:41 - loss: 10.6121 - categorical_accuracy: 0.2612 - precision: 0.7515 - recall: 0.1717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:02:26 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:02:26 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:02:27 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:02:27 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:02:27 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:02:27 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "399/500 [======================>.......] - ETA: 49s - loss: 8.1532 - categorical_accuracy: 0.4230 - precision: 0.7664 - recall: 0.3780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:03:56 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:03:56 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:03:56 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:03:56 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:03:56 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:03:56 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "500/500 [==============================] - 243s 486ms/step - loss: 7.2663 - categorical_accuracy: 0.4730 - precision: 0.7642 - recall: 0.4527\n",
      "Epoch 2/5\n",
      " 99/500 [====>.........................] - ETA: 3:04 - loss: 2.8351 - categorical_accuracy: 0.6901 - precision: 0.7600 - recall: 0.8077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:05:28 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:05:28 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:05:28 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:05:28 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:05:28 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:05:28 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "299/500 [================>.............] - ETA: 1:32 - loss: 2.5892 - categorical_accuracy: 0.7060 - precision: 0.7616 - recall: 0.8251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:07:01 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:07:01 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:07:01 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:07:01 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:07:01 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:07:01 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.4012 - categorical_accuracy: 0.7161 - precision: 0.7645 - recall: 0.8377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:08:34 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:08:34 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:08:34 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:08:34 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:08:34 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:08:34 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "500/500 [==============================] - 232s 464ms/step - loss: 2.3998 - categorical_accuracy: 0.7163 - precision: 0.7646 - recall: 0.8378\n",
      "Epoch 3/5\n",
      "199/500 [==========>...................] - ETA: 2:14 - loss: 1.8872 - categorical_accuracy: 0.7356 - precision: 0.7665 - recall: 0.8707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:10:04 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:10:04 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:10:04 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:10:04 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:10:04 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:10:04 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "399/500 [======================>.......] - ETA: 45s - loss: 1.8151 - categorical_accuracy: 0.7388 - precision: 0.7677 - recall: 0.8751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:11:33 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:11:33 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:11:33 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:11:33 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:11:33 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:11:33 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "500/500 [==============================] - 223s 447ms/step - loss: 1.8068 - categorical_accuracy: 0.7398 - precision: 0.7679 - recall: 0.8754\n",
      "Epoch 4/5\n",
      " 99/500 [====>.........................] - ETA: 2:57 - loss: 1.6759 - categorical_accuracy: 0.7318 - precision: 0.7559 - recall: 0.8810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:13:02 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:13:02 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:13:02 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:13:02 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:13:02 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:13:02 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "299/500 [================>.............] - ETA: 1:29 - loss: 1.6195 - categorical_accuracy: 0.7449 - precision: 0.7666 - recall: 0.8866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:14:31 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:14:31 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:14:31 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:14:31 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:14:31 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:14:31 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.5836 - categorical_accuracy: 0.7495 - precision: 0.7696 - recall: 0.8891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:16:01 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:16:01 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:16:01 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:16:01 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:16:01 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:16:01 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "500/500 [==============================] - 223s 447ms/step - loss: 1.5858 - categorical_accuracy: 0.7495 - precision: 0.7697 - recall: 0.8890\n",
      "Epoch 5/5\n",
      "199/500 [==========>...................] - ETA: 2:13 - loss: 1.4816 - categorical_accuracy: 0.7525 - precision: 0.7684 - recall: 0.8950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:17:30 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:17:30 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:17:30 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:17:30 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:17:30 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:17:30 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "399/500 [======================>.......] - ETA: 44s - loss: 1.4305 - categorical_accuracy: 0.7559 - precision: 0.7708 - recall: 0.8986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:18:59 callbacks:236] Logged 'batch' metrics to mlflow-lite\n",
      "[I 200426 12:18:59 callbacks:236] Logged 'size' metrics to mlflow-lite\n",
      "[I 200426 12:18:59 callbacks:236] Logged 'loss' metrics to mlflow-lite\n",
      "[I 200426 12:18:59 callbacks:236] Logged 'categorical_accuracy' metrics to mlflow-lite\n",
      "[I 200426 12:18:59 callbacks:236] Logged 'precision' metrics to mlflow-lite\n",
      "[I 200426 12:18:59 callbacks:236] Logged 'recall' metrics to mlflow-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4421 - categorical_accuracy: 0.7561 - precision: 0.7707 - recall: 0.8978\n",
      "Epoch 00005: saving model to /tmp/deeplab_demo/checkpoints/test_deeplab_05.h5\n",
      "500/500 [==============================] - 336s 672ms/step - loss: 1.4421 - categorical_accuracy: 0.7562 - precision: 0.7709 - recall: 0.8978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200426 12:21:37 <ipython-input-3-fecc709d05cb>:23] getting inference model ..\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/tmp/deeplab_demo/test_deeplab_5.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fecc709d05cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getting inference model ..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcheckpoint_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tmp/deeplab_demo/test_deeplab_{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpred_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'creating coco style predictions ..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/edge/segmentation/deeplab_v3/utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36medge.segmentation.deeplab_v3.utils.model_loader\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    181\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1365\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1366\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/tmp/deeplab_demo/test_deeplab_5.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "for i in [5, 10]:\n",
    "    train(\n",
    "          resize_height=600,\n",
    "          resize_width=600,\n",
    "          num_epochs=i,\n",
    "          batch_size=2,\n",
    "          checkpoint_prefix='test_deeplab',\n",
    "          snapshot_every_epoch=5,\n",
    "          output_stride=16,\n",
    "          atrous_rates=(6,12,18),\n",
    "          checkpoint_path=None,\n",
    "          steps_per_epoch=None,\n",
    "          initial_epoch=i-5,\n",
    "          weights='pascal_voc', # pascal_voc, cityscapes, path to h5 file trained with edge\n",
    "          aug=None, # coming soon\n",
    "          lr=1e-5,\n",
    "          backbone_network='xception', # xception, mobilenetv2\n",
    "          print_summary=False,\n",
    "          mlflowlite_log_step=200,\n",
    "          distribute_strategy=None)\n",
    "\n",
    "\n",
    "    logger.info('getting inference model ..')\n",
    "    checkpoint_file = '/tmp/deeplab_demo/test_deeplab_{}.h5'.format(i)\n",
    "    pred_model = get_inference_model(checkpoint_file)\n",
    "\n",
    "    logger.info('creating coco style predictions ..')\n",
    "    json_saver = CocoEvaluator(\n",
    "      model=pred_model, \n",
    "      coco_gt='/tmp/segm_gt.json', #get this from above\n",
    "      coco_dt='/tmp/segm_pred.json') \n",
    "    #json_saver.run(image_dir=None, threshold=0.5)\n",
    "\n",
    "    cocoGt = COCO('/tmp/segm_gt.json')\n",
    "    cocoDt = cocoGt.loadRes('/tmp/segm_pred.json')\n",
    "\n",
    "    #logger.info('Evaluating metrics on COCO-Stuff-Evaluation ...')\n",
    "    #CocoStuffEvaluator = COCOStuffeval(cocoGt,cocoDt,0,255)\n",
    "    #CocoStuffEvaluator.evaluate()\n",
    "    #stats, statsClass = CocoStuffEvaluator.summarize()\n",
    "\n",
    "    logger.info('Evaluating metrics on COCO Evaluation ...')\n",
    "    cocoEval = COCOeval(cocoGt=cocoGt, cocoDt=cocoDt, iouType='segm')\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "\n",
    "    if get_experiment_id():\n",
    "          logger.info('logging to mlflow-lite')\n",
    "          log_metrics(metrics=statsClass, step=num_epoch)\n",
    "          log_metrics(\n",
    "                metrics={\n",
    "                'miou':stats[0].item(),\n",
    "                'fwiou':stats[1].item(),\n",
    "                'mean-acc':stats[2].item(),\n",
    "                'pixel-acc':stats[3].item()},\n",
    "                step=num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
